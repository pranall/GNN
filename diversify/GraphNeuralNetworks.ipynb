{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7cx0kEcm09iB",
        "outputId": "96426509-dfc7-4d61-a9ae-cdf86d41421a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.1.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m568.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.2)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "Successfully installed torch-2.1.0+cu118 torchaudio-2.1.0+cu118 torchvision-0.16.0+cu118 triton-2.1.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/pyg_lib-0.4.0%2Bpt21cu118-cp311-cp311-linux_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp311-cp311-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp311-cp311-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_cluster-1.6.3%2Bpt21cu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt21cu118-cp311-cp311-linux_x86_64.whl (891 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.8/891.8 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt21cu118 torch_cluster-1.6.3+pt21cu118 torch_scatter-2.1.2+pt21cu118 torch_sparse-0.6.18+pt21cu118 torch_spline_conv-1.2.2+pt21cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.6.15)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting fastdtw\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp311-cp311-linux_x86_64.whl size=542093 sha256=96c29c77e5ce34e98e7ab7feaea5f8f40796825d9595b01ecb91b72ecbf280f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/8a/f6/fd3df9a9714677410a5ccbf3ca519e66db4a54a1c46ea95332\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: numpy, fastdtw\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastdtw-0.3.4 numpy-1.24.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "19c555d6065a422091215213526591ad",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# First, uninstall existing PyTorch to avoid conflicts\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "\n",
        "# Install PyTorch 2.1.0 with CUDA 11.8 (latest stable version)\n",
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install PyTorch Geometric (PyG) dependencies (FOR TORCH 2.1.0 + CUDA 11.8)\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Install other required packages\n",
        "!pip install fastdtw numpy==1.24.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KGIQTzg1NW9",
        "outputId": "71c26fb7-1e3c-4b55-ca92-62860d896076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GNN'...\n",
            "remote: Enumerating objects: 2972, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 2972 (delta 86), reused 3 (delta 3), pack-reused 2795 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2972/2972), 858.29 KiB | 17.88 MiB/s, done.\n",
            "Resolving deltas: 100% (1430/1430), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pranall/GNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmfgfmk61Ppy",
        "outputId": "5e21d5b9-8676-4ea3-edc7-e3b9753996c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/GNN/diversify\n"
          ]
        }
      ],
      "source": [
        "%cd /content/GNN/diversify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITUYIv971R9x",
        "outputId": "f9b0a2be-5c23-4d48-bab4-010e79529842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-07-07 07:46:40--  https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
            "Resolving wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)... 20.60.131.4\n",
            "Connecting to wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)|20.60.131.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20237244 (19M) [application/zip]\n",
            "Saving to: ‘diversity_emg.zip’\n",
            "\n",
            "diversity_emg.zip   100%[===================>]  19.30M  3.76MB/s    in 5.1s    \n",
            "\n",
            "2025-07-07 07:46:46 (3.76 MB/s) - ‘diversity_emg.zip’ saved [20237244/20237244]\n",
            "\n",
            "Archive:  diversity_emg.zip\n",
            "   creating: emg/\n",
            "   creating: emg/20/\n",
            "  inflating: emg/20/1_raw_data_11-41_22.03.16.txt  \n",
            "  inflating: emg/20/2_raw_data_11-43_22.03.16.txt  \n",
            "   creating: emg/35/\n",
            "  inflating: emg/35/2_raw_data_10-05_13.04.16.txt  \n",
            "  inflating: emg/35/1_raw_data_10-03_13.04.16.txt  \n",
            "   creating: emg/09/\n",
            "  inflating: emg/09/1_raw_data_12-41_23.03.16.txt  \n",
            "  inflating: emg/09/2_raw_data_12-43_23.03.16.txt  \n",
            "   creating: emg/15/\n",
            "  inflating: emg/15/2_raw_data_08-51_13.04.16.txt  \n",
            "  inflating: emg/15/1_raw_data_08-49_13.04.16.txt  \n",
            "   creating: emg/22/\n",
            "  inflating: emg/22/1_raw_data_12-37_28.03.16.txt  \n",
            "  inflating: emg/22/2_raw_data_12-39_28.03.16.txt  \n",
            "   creating: emg/13/\n",
            "  inflating: emg/13/1_raw_data_13-26_21.03.16.txt  \n",
            "  inflating: emg/13/2_raw_data_13-29_21.03.16.txt  \n",
            "   creating: emg/30/\n",
            "  inflating: emg/30/1_raw_data_09-49_21.03.16.txt  \n",
            "  inflating: emg/30/2_raw_data_09-50_21.03.16.txt  \n",
            "   creating: emg/01/\n",
            "  inflating: emg/01/2_raw_data_13-13_22.03.16.txt  \n",
            "  inflating: emg/01/1_raw_data_13-12_22.03.16.txt  \n",
            "   creating: emg/28/\n",
            "  inflating: emg/28/1_raw_data_12-10_15.04.16.txt  \n",
            "  inflating: emg/28/2_raw_data_12-11_15.04.16.txt  \n",
            "  inflating: emg/README.txt          \n",
            "   creating: emg/34/\n",
            "  inflating: emg/34/2_raw_data_10-53_07.04.16.txt  \n",
            "  inflating: emg/34/1_raw_data_10-51_07.04.16.txt  \n",
            "   creating: emg/06/\n",
            "  inflating: emg/06/2_raw_data_10-40_11.04.16.txt  \n",
            "  inflating: emg/06/1_raw_data_10-38_11.04.16.txt  \n",
            "   creating: emg/25/\n",
            "  inflating: emg/25/2_raw_data_14-53_24.04.16.txt  \n",
            "  inflating: emg/25/1_raw_data_14-51_24.04.16.txt  \n",
            "   creating: emg/26/\n",
            "  inflating: emg/26/2_raw_data_10-23_29.03.16.txt  \n",
            "  inflating: emg/26/1_raw_data_10-22_29.03.16.txt  \n",
            "   creating: emg/36/\n",
            "  inflating: emg/36/1_raw_data_13-03_15.04.16.txt  \n",
            "  inflating: emg/36/2_raw_data_13-04_15.04.16.txt  \n",
            "   creating: emg/04/\n",
            "  inflating: emg/04/1_raw_data_18-02_24.04.16.txt  \n",
            "  inflating: emg/04/2_raw_data_18-03_24.04.16.txt  \n",
            "   creating: emg/14/\n",
            "  inflating: emg/14/2_raw_data_09-51_15.04.16.txt  \n",
            "  inflating: emg/14/1_raw_data_09-50_15.04.16.txt  \n",
            "   creating: emg/02/\n",
            "  inflating: emg/02/2_raw_data_14-21_22.03.16.txt  \n",
            "  inflating: emg/02/1_raw_data_14-19_22.03.16.txt  \n",
            "   creating: emg/27/\n",
            "  inflating: emg/27/1_raw_data_12-19_06.04.16.txt  \n",
            "  inflating: emg/27/2_raw_data_12-20_06.04.16.txt  \n",
            "   creating: emg/17/\n",
            "  inflating: emg/17/2_raw_data_11-20_23.03.16.txt  \n",
            "  inflating: emg/17/1_raw_data_11-19_23.03.16.txt  \n",
            "  inflating: emg/emg_x.npy           \n",
            "   creating: emg/03/\n",
            "  inflating: emg/03/1_raw_data_09-32_11.04.16.txt  \n",
            "  inflating: emg/03/2_raw_data_09-34_11.04.16.txt  \n",
            "   creating: emg/31/\n",
            "  inflating: emg/31/2_raw_data_11-16_11.04.16.txt  \n",
            "  inflating: emg/31/1_raw_data_11-15_11.04.16.txt  \n",
            "   creating: emg/11/\n",
            "  inflating: emg/11/1_raw_data_13-11_18.03.16.txt  \n",
            "  inflating: emg/11/2_raw_data_13-13_18.03.16.txt  \n",
            "   creating: emg/21/\n",
            "  inflating: emg/21/2_raw_data_20-30_24.04.16.txt  \n",
            "  inflating: emg/21/1_raw_data_20-28_24.04.16.txt  \n",
            "   creating: emg/10/\n",
            "  inflating: emg/10/1_raw_data_11-08_21.03.16.txt  \n",
            "  inflating: emg/10/2_raw_data_11-10_21.03.16.txt  \n",
            "   creating: emg/05/\n",
            "  inflating: emg/05/2_raw_data_10-29_30.03.16.txt  \n",
            "  inflating: emg/05/1_raw_data_10-28_30.03.16.txt  \n",
            "   creating: emg/19/\n",
            "  inflating: emg/19/1_raw_data_12-10_26.04.16.txt  \n",
            "  inflating: emg/19/2_raw_data_12-11_26.04.16.txt  \n",
            "   creating: emg/08/\n",
            "  inflating: emg/08/1_raw_data_12-14_23.03.16.txt  \n",
            "  inflating: emg/08/2_raw_data_12-16_23.03.16.txt  \n",
            "   creating: emg/12/\n",
            "  inflating: emg/12/2_raw_data_11-36_28.03.16.txt  \n",
            "  inflating: emg/12/1_raw_data_11-35_28.03.16.txt  \n",
            "   creating: emg/16/\n",
            "  inflating: emg/16/2_raw_data_12-14_25.04.16.txt  \n",
            "  inflating: emg/16/1_raw_data_12-12_25.04.16.txt  \n",
            "   creating: emg/24/\n",
            "  inflating: emg/24/1_raw_data_10-16_12.04.16.txt  \n",
            "  inflating: emg/24/2_raw_data_10-17_12.04.16.txt  \n",
            "   creating: emg/33/\n",
            "  inflating: emg/33/2_raw_data_09-50_12.04.16.txt  \n",
            "  inflating: emg/33/1_raw_data_09-49_12.04.16.txt  \n",
            "   creating: emg/07/\n",
            "  inflating: emg/07/2_raw_data_18-50_22.03.16.txt  \n",
            "  inflating: emg/07/1_raw_data_18-48_22.03.16.txt  \n",
            "   creating: emg/32/\n",
            "  inflating: emg/32/2_raw_data_12-06_27.04.16.txt  \n",
            "  inflating: emg/32/1_raw_data_12-04_27.04.16.txt  \n",
            "   creating: emg/18/\n",
            "  inflating: emg/18/1_raw_data_12-35_21.03.16.txt  \n",
            "  inflating: emg/18/2_raw_data_12-37_21.03.16.txt  \n",
            "   creating: emg/23/\n",
            "  inflating: emg/23/1_raw_data_13-18_05.04.16.txt  \n",
            "  inflating: emg/23/2_raw_data_13-19_05.04.16.txt  \n",
            "   creating: emg/29/\n",
            "  inflating: emg/29/2_raw_data_10-18_15.04.16.txt  \n",
            "  inflating: emg/29/1_raw_data_10-17_15.04.16.txt  \n",
            "  inflating: emg/emg_y.npy           \n"
          ]
        }
      ],
      "source": [
        "# Download and prepare dataset\n",
        "!wget https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
        "!unzip diversity_emg.zip\n",
        "!mkdir -p ./data/emg\n",
        "!mv emg ./data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fVx9GMGe1Vi4"
      },
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "!mkdir -p ./data/train_output/act/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfPnKszH1Xnr",
        "outputId": "d721cfff-b310-4d45-885c-5e15af9d466a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Using graph_threshold: -1.0\n",
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.1.0+cu118\n",
            "\tTorchvision: 0.16.0+cu118\n",
            "\tCUDA: 11.8\n",
            "\tCUDNN: 8700\n",
            "\tNumPy: 1.24.3\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "model_type: gnn\n",
            "algorithm: diversify\n",
            "alpha: 0.1\n",
            "alpha1: 0.1\n",
            "batch_size: 32\n",
            "beta1: 0.5\n",
            "checkpoint_freq: 100\n",
            "local_epoch: 3\n",
            "max_epoch: 5\n",
            "lr: 0.001\n",
            "lr_decay1: 1.0\n",
            "lr_decay2: 1.0\n",
            "weight_decay: 0.0005\n",
            "dropout: 0.0\n",
            "label_smoothing: 0.0\n",
            "bottleneck: 256\n",
            "classifier: linear\n",
            "dis_hidden: 256\n",
            "layer: bn\n",
            "model_size: median\n",
            "lam: 0.0\n",
            "latent_domain_num: 4\n",
            "domain_num: 0\n",
            "data_file: \n",
            "dataset: emg\n",
            "data_dir: ./data/\n",
            "task: cross_people\n",
            "test_envs: [0]\n",
            "N_WORKERS: 2\n",
            "automated_k: False\n",
            "curriculum: False\n",
            "CL_PHASE_EPOCHS: 5\n",
            "enable_shap: False\n",
            "resume: None\n",
            "debug_mode: False\n",
            "use_gnn: True\n",
            "gnn_hidden_dim: 32\n",
            "gnn_output_dim: 128\n",
            "gnn_lr: 0.001\n",
            "gnn_weight_decay: 0.0001\n",
            "gnn_pretrain_epochs: 5\n",
            "gpu_id: 0\n",
            "seed: 42\n",
            "output: ./data/train_output/\n",
            "old: False\n",
            "steps_per_epoch: 100\n",
            "select_position: {'emg': [0]}\n",
            "select_channel: {'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list: {'emg': 1000}\n",
            "act_people: {'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "input_shape: (8, 1, 200)\n",
            "num_classes: 6\n",
            "grid_size: 10\n",
            "graph_threshold: -1.0\n",
            "\n",
            "Using device: cuda\n",
            "✅ GNN (TemporalGCN) is active for training.\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache MISS ❌\n",
            "⏳ Precomputing graphs...\n",
            "Processing batches:   0%|          | 0/27 [00:00<?, ?it/s]BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Processing batches: 100%|##########| 27/27 [15:34<00:00, 34.63s/it]\n",
            "✅ Saved 6883 precomputed graphs\n",
            "💻 Memory After Graphs - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔎 RAW SAMPLE TYPE: <class 'tuple'>\n",
            "  sample tuple shapes: [<class 'torch_geometric.data.data.Data'>, <class 'int'>, <class 'int'>]\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "Class distribution: {0: 3420, 1: 3324, 2: 3432, 3: 3525, 4: 3465, 5: 3483}\n",
            "Class distribution: {0: 1140, 1: 1108, 2: 1144, 3: 1175, 4: 1155, 5: 1161}\n",
            "Train samples: 4143, Val samples: 1036, Target samples: 1704\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "🔎 BATCH X type     : <class 'abc.DataBatch'>\n",
            " x.x.shape          : torch.Size([6400, 8])\n",
            " x.edge_index.shape: torch.Size([2, 6400])\n",
            " x.batch.shape      : torch.Size([6400])\n",
            " labels y.shape     : torch.Size([32])\n",
            " domains d.shape    : torch.Size([32])\n",
            "Initializing GNN feature extractor...\n",
            "✅ Quick GNN smoke test output shape: torch.Size([1, 128])\n",
            ">>> ABOUT TO START EPOCH LOOP\n",
            "Epoch 1/5 — Train: 0.1740, Val: 0.1680, Time: 875.6s\n",
            "Epoch 2/5 — Train: 0.1627, Val: 0.1651, Time: 907.7s\n",
            "Epoch 3/5 — Train: 0.1627, Val: 0.1651, Time: 883.8s\n",
            "Epoch 4/5 — Train: 0.1627, Val: 0.1651, Time: 877.7s\n",
            "Epoch 5/5 — Train: 0.1627, Val: 0.1651, Time: 884.8s\n",
            "Training complete. Best validation accuracy: 0.1680\n"
          ]
        }
      ],
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --dataset emg \\\n",
        "  --max_epoch 5 \\\n",
        "  --local_epoch 3 \\\n",
        "  --lr 0.001 \\\n",
        "  --batch_size 32 \\\n",
        "  --seed 42 \\\n",
        "  --output ./data/train_output/ \\\n",
        "  --use_gnn \\\n",
        "  --model_type gnn \\\n",
        "  --test_envs 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh_Nq1jY1alI",
        "outputId": "5c0d0db6-440c-42f3-aec1-02bfb73e552f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Using graph_threshold: -1.0\n",
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.1.0+cu118\n",
            "\tTorchvision: 0.16.0+cu118\n",
            "\tCUDA: 11.8\n",
            "\tCUDNN: 8700\n",
            "\tNumPy: 1.24.3\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "model_type: gnn\n",
            "algorithm: diversify\n",
            "alpha: 0.1\n",
            "alpha1: 0.1\n",
            "batch_size: 32\n",
            "beta1: 0.5\n",
            "checkpoint_freq: 100\n",
            "local_epoch: 3\n",
            "max_epoch: 10\n",
            "lr: 0.001\n",
            "lr_decay1: 1.0\n",
            "lr_decay2: 1.0\n",
            "weight_decay: 0.0005\n",
            "dropout: 0.0\n",
            "label_smoothing: 0.0\n",
            "bottleneck: 256\n",
            "classifier: linear\n",
            "dis_hidden: 256\n",
            "layer: bn\n",
            "model_size: median\n",
            "lam: 0.0\n",
            "latent_domain_num: 4\n",
            "domain_num: 0\n",
            "data_file: \n",
            "dataset: emg\n",
            "data_dir: ./data/\n",
            "task: cross_people\n",
            "test_envs: [0]\n",
            "N_WORKERS: 2\n",
            "automated_k: False\n",
            "curriculum: False\n",
            "CL_PHASE_EPOCHS: 5\n",
            "enable_shap: False\n",
            "resume: None\n",
            "debug_mode: False\n",
            "use_gnn: True\n",
            "gnn_hidden_dim: 32\n",
            "gnn_output_dim: 128\n",
            "gnn_lr: 0.001\n",
            "gnn_weight_decay: 0.0001\n",
            "gnn_pretrain_epochs: 5\n",
            "gpu_id: 0\n",
            "seed: 42\n",
            "output: ./data/train_output/\n",
            "old: False\n",
            "steps_per_epoch: 100\n",
            "select_position: {'emg': [0]}\n",
            "select_channel: {'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list: {'emg': 1000}\n",
            "act_people: {'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "input_shape: (8, 1, 200)\n",
            "num_classes: 6\n",
            "grid_size: 10\n",
            "graph_threshold: -1.0\n",
            "\n",
            "Using device: cuda\n",
            "✅ GNN (TemporalGCN) is active for training.\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 RAW SAMPLE TYPE: <class 'tuple'>\n",
            "  sample tuple shapes: [<class 'torch_geometric.data.data.Data'>, <class 'int'>, <class 'int'>]\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "Class distribution: {0: 3420, 1: 3324, 2: 3432, 3: 3525, 4: 3465, 5: 3483}\n",
            "Class distribution: {0: 1140, 1: 1108, 2: 1144, 3: 1175, 4: 1155, 5: 1161}\n",
            "Train samples: 4143, Val samples: 1036, Target samples: 1704\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "🔎 BATCH X type     : <class 'abc.DataBatch'>\n",
            " x.x.shape          : torch.Size([6400, 8])\n",
            " x.edge_index.shape: torch.Size([2, 6400])\n",
            " x.batch.shape      : torch.Size([6400])\n",
            " labels y.shape     : torch.Size([32])\n",
            " domains d.shape    : torch.Size([32])\n",
            "Initializing GNN feature extractor...\n",
            "✅ Quick GNN smoke test output shape: torch.Size([1, 128])\n",
            ">>> ABOUT TO START EPOCH LOOP\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 1/10 — Train: 0.1740, Val: 0.1680, Time: 881.0s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 2/10 — Train: 0.1627, Val: 0.1651, Time: 879.8s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 3/10 — Train: 0.1627, Val: 0.1651, Time: 875.4s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 4/10 — Train: 0.1627, Val: 0.1651, Time: 866.3s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 5/10 — Train: 0.1627, Val: 0.1651, Time: 877.8s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 6/10 — Train: 0.1740, Val: 0.1680, Time: 876.6s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 7/10 — Train: 0.1740, Val: 0.1680, Time: 877.2s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 8/10 — Train: 0.1740, Val: 0.1680, Time: 881.4s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 9/10 — Train: 0.1740, Val: 0.1680, Time: 878.9s\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 10/10 — Train: 0.1740, Val: 0.1680, Time: 881.1s\n",
            "Training complete. Best validation accuracy: 0.1680\n"
          ]
        }
      ],
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --dataset emg \\\n",
        "  --max_epoch 10 \\\n",
        "  --local_epoch 3 \\\n",
        "  --lr 0.001 \\\n",
        "  --batch_size 32 \\\n",
        "  --seed 42 \\\n",
        "  --output ./data/train_output/ \\\n",
        "  --use_gnn \\\n",
        "  --model_type gnn \\\n",
        "  --test_envs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KyYnoL51dO6",
        "outputId": "ffc31e54-0909-42b2-eee3-519b4b8eed71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Using graph_threshold: -1.0\n",
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.1.0+cu118\n",
            "\tTorchvision: 0.16.0+cu118\n",
            "\tCUDA: 11.8\n",
            "\tCUDNN: 8700\n",
            "\tNumPy: 1.24.3\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "model_type: gnn\n",
            "algorithm: diversify\n",
            "alpha: 0.1\n",
            "alpha1: 0.1\n",
            "batch_size: 32\n",
            "beta1: 0.5\n",
            "checkpoint_freq: 100\n",
            "local_epoch: 3\n",
            "max_epoch: 15\n",
            "lr: 0.001\n",
            "lr_decay1: 1.0\n",
            "lr_decay2: 1.0\n",
            "weight_decay: 0.0005\n",
            "dropout: 0.0\n",
            "label_smoothing: 0.0\n",
            "bottleneck: 256\n",
            "classifier: linear\n",
            "dis_hidden: 256\n",
            "layer: bn\n",
            "model_size: median\n",
            "lam: 0.0\n",
            "latent_domain_num: 4\n",
            "domain_num: 0\n",
            "data_file: \n",
            "dataset: emg\n",
            "data_dir: ./data/\n",
            "task: cross_people\n",
            "test_envs: [0]\n",
            "N_WORKERS: 2\n",
            "automated_k: False\n",
            "curriculum: False\n",
            "CL_PHASE_EPOCHS: 5\n",
            "enable_shap: False\n",
            "resume: None\n",
            "debug_mode: False\n",
            "use_gnn: True\n",
            "gnn_hidden_dim: 32\n",
            "gnn_output_dim: 128\n",
            "gnn_lr: 0.001\n",
            "gnn_weight_decay: 0.0001\n",
            "gnn_pretrain_epochs: 5\n",
            "gpu_id: 0\n",
            "seed: 42\n",
            "output: ./data/train_output/\n",
            "old: False\n",
            "steps_per_epoch: 100\n",
            "select_position: {'emg': [0]}\n",
            "select_channel: {'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list: {'emg': 1000}\n",
            "act_people: {'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "input_shape: (8, 1, 200)\n",
            "num_classes: 6\n",
            "grid_size: 10\n",
            "graph_threshold: -1.0\n",
            "\n",
            "Using device: cuda\n",
            "✅ GNN (TemporalGCN) is active for training.\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 RAW SAMPLE TYPE: <class 'tuple'>\n",
            "  sample tuple shapes: [<class 'torch_geometric.data.data.Data'>, <class 'int'>, <class 'int'>]\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "🔎 Raw data shapes:\n",
            "  x: (6883, 8, 200)\n",
            "  cy: (6883,)\n",
            "  py: (6883,)\n",
            "  sy: (6883,)\n",
            "  👤 Person 0 initial samples: 187\n",
            "    → After adding: self.x.shape = (187, 8, 200), self.labels.shape = (187,)\n",
            "  👤 Person 1 initial samples: 191\n",
            "    → After adding: self.x.shape = (378, 8, 200), self.labels.shape = (378,)\n",
            "  👤 Person 2 initial samples: 172\n",
            "    → After adding: self.x.shape = (550, 8, 200), self.labels.shape = (550,)\n",
            "  👤 Person 3 initial samples: 208\n",
            "    → After adding: self.x.shape = (758, 8, 200), self.labels.shape = (758,)\n",
            "  👤 Person 4 initial samples: 182\n",
            "    → After adding: self.x.shape = (940, 8, 200), self.labels.shape = (940,)\n",
            "  👤 Person 5 initial samples: 186\n",
            "    → After adding: self.x.shape = (1126, 8, 200), self.labels.shape = (1126,)\n",
            "  👤 Person 6 initial samples: 237\n",
            "    → After adding: self.x.shape = (1363, 8, 200), self.labels.shape = (1363,)\n",
            "  👤 Person 7 initial samples: 170\n",
            "    → After adding: self.x.shape = (1533, 8, 200), self.labels.shape = (1533,)\n",
            "  👤 Person 8 initial samples: 171\n",
            "    → After adding: self.x.shape = (1704, 8, 200), self.labels.shape = (1704,)\n",
            "  👤 Person 9 initial samples: 189\n",
            "    → After adding: self.x.shape = (1893, 8, 200), self.labels.shape = (1893,)\n",
            "  👤 Person 10 initial samples: 196\n",
            "    → After adding: self.x.shape = (2089, 8, 200), self.labels.shape = (2089,)\n",
            "  👤 Person 11 initial samples: 200\n",
            "    → After adding: self.x.shape = (2289, 8, 200), self.labels.shape = (2289,)\n",
            "  👤 Person 12 initial samples: 292\n",
            "    → After adding: self.x.shape = (2581, 8, 200), self.labels.shape = (2581,)\n",
            "  👤 Person 13 initial samples: 171\n",
            "    → After adding: self.x.shape = (2752, 8, 200), self.labels.shape = (2752,)\n",
            "  👤 Person 14 initial samples: 182\n",
            "    → After adding: self.x.shape = (2934, 8, 200), self.labels.shape = (2934,)\n",
            "  👤 Person 15 initial samples: 195\n",
            "    → After adding: self.x.shape = (3129, 8, 200), self.labels.shape = (3129,)\n",
            "  👤 Person 16 initial samples: 185\n",
            "    → After adding: self.x.shape = (3314, 8, 200), self.labels.shape = (3314,)\n",
            "  👤 Person 17 initial samples: 204\n",
            "    → After adding: self.x.shape = (3518, 8, 200), self.labels.shape = (3518,)\n",
            "  👤 Person 18 initial samples: 195\n",
            "    → After adding: self.x.shape = (3713, 8, 200), self.labels.shape = (3713,)\n",
            "  👤 Person 19 initial samples: 192\n",
            "    → After adding: self.x.shape = (3905, 8, 200), self.labels.shape = (3905,)\n",
            "  👤 Person 20 initial samples: 175\n",
            "    → After adding: self.x.shape = (4080, 8, 200), self.labels.shape = (4080,)\n",
            "  👤 Person 21 initial samples: 173\n",
            "    → After adding: self.x.shape = (4253, 8, 200), self.labels.shape = (4253,)\n",
            "  👤 Person 22 initial samples: 215\n",
            "    → After adding: self.x.shape = (4468, 8, 200), self.labels.shape = (4468,)\n",
            "  👤 Person 23 initial samples: 194\n",
            "    → After adding: self.x.shape = (4662, 8, 200), self.labels.shape = (4662,)\n",
            "  👤 Person 24 initial samples: 164\n",
            "    → After adding: self.x.shape = (4826, 8, 200), self.labels.shape = (4826,)\n",
            "  👤 Person 25 initial samples: 173\n",
            "    → After adding: self.x.shape = (4999, 8, 200), self.labels.shape = (4999,)\n",
            "  👤 Person 26 initial samples: 191\n",
            "    → After adding: self.x.shape = (5190, 8, 200), self.labels.shape = (5190,)\n",
            "  👤 Person 27 initial samples: 140\n",
            "    → After adding: self.x.shape = (5330, 8, 200), self.labels.shape = (5330,)\n",
            "  👤 Person 28 initial samples: 197\n",
            "    → After adding: self.x.shape = (5527, 8, 200), self.labels.shape = (5527,)\n",
            "  👤 Person 29 initial samples: 208\n",
            "    → After adding: self.x.shape = (5735, 8, 200), self.labels.shape = (5735,)\n",
            "  👤 Person 30 initial samples: 165\n",
            "    → After adding: self.x.shape = (5900, 8, 200), self.labels.shape = (5900,)\n",
            "  👤 Person 31 initial samples: 237\n",
            "    → After adding: self.x.shape = (6137, 8, 200), self.labels.shape = (6137,)\n",
            "  👤 Person 32 initial samples: 179\n",
            "    → After adding: self.x.shape = (6316, 8, 200), self.labels.shape = (6316,)\n",
            "  👤 Person 33 initial samples: 209\n",
            "    → After adding: self.x.shape = (6525, 8, 200), self.labels.shape = (6525,)\n",
            "  👤 Person 34 initial samples: 191\n",
            "    → After adding: self.x.shape = (6716, 8, 200), self.labels.shape = (6716,)\n",
            "  👤 Person 35 initial samples: 167\n",
            "    → After adding: self.x.shape = (6883, 8, 200), self.labels.shape = (6883,)\n",
            "✅ After comb_position: self.x.shape = (6883, 8, 200) self.labels.shape = (6883,)\n",
            "🎯 FINAL ActList sample count: 6883\n",
            "💻 Memory Info - Allocated: 0.00MB | Reserved: 0.00MB\n",
            "🔍 Graph cache HIT ✅ — Loading from ./data/train_output//precomputed_graphs.pt\n",
            "✅ Loaded 6883 precomputed graphs\n",
            "Class distribution: {0: 3420, 1: 3324, 2: 3432, 3: 3525, 4: 3465, 5: 3483}\n",
            "Class distribution: {0: 1140, 1: 1108, 2: 1144, 3: 1175, 4: 1155, 5: 1161}\n",
            "Train samples: 4143, Val samples: 1036, Target samples: 1704\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "🔎 BATCH X type     : <class 'abc.DataBatch'>\n",
            " x.x.shape          : torch.Size([6400, 8])\n",
            " x.edge_index.shape: torch.Size([2, 6400])\n",
            " x.batch.shape      : torch.Size([6400])\n",
            " labels y.shape     : torch.Size([32])\n",
            " domains d.shape    : torch.Size([32])\n",
            "Initializing GNN feature extractor...\n",
            "✅ Quick GNN smoke test output shape: torch.Size([1, 128])\n",
            ">>> ABOUT TO START EPOCH LOOP\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "BEFORE SHAPE CHANGE, x.shape: torch.Size([8, 1, 200])\n",
            "AFTER SHAPE CHANGE, x.shape: torch.Size([200, 8])\n",
            "IN _to_graph, input x.shape: torch.Size([200, 8])\n",
            "Epoch 1/15 — Train: 0.1740, Val: 0.1680, Time: 882.7s\n"
          ]
        }
      ],
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --dataset emg \\\n",
        "  --max_epoch 15 \\\n",
        "  --local_epoch 3 \\\n",
        "  --lr 0.001 \\\n",
        "  --batch_size 32 \\\n",
        "  --seed 42 \\\n",
        "  --output ./data/train_output/ \\\n",
        "  --use_gnn \\\n",
        "  --model_type gnn \\\n",
        "  --test_envs 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --dataset emg \\\n",
        "  --max_epoch 15 \\\n",
        "  --local_epoch 3 \\\n",
        "  --lr 0.001 \\\n",
        "  --batch_size 32 \\\n",
        "  --seed 42 \\\n",
        "  --output ./data/train_output/ \\\n",
        "  --use_gnn \\\n",
        "  --model_type gnn \\\n",
        "  --test_envs 3"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
